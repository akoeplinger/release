#!/usr/bin/env python

import commands
import os
import os.path
import sys
import shutil
import pdb
import glob
import re
import distutils.dir_util
import threading

sys.path += ['../../pyutils']
import config
import utils
import packaging

# Constants
# Which noarch packages to include in the various packages
packages_to_include = {}

packages_to_include['macos-10-ppc'] = ['mono', 'cocoa-sharp', 'libgdiplus', 'xsp', 'monodoc', 'boo', 'ikvm', 'nant', 'ironpython', 'mono-basic' ]

packages_to_include['macos-10-x86'] = packages_to_include['macos-10-ppc']

# Seems x86 must be first, so that's where the merge takes place
archs = [ 'macos-10-x86', 'macos-10-ppc' ]

debug=1

####  Main execution ####
# Collect args
try:
	try:
		(script_name, target, version) = sys.argv
		release = "0"
	except:
		(script_name, target, version, release) = sys.argv

except:

	print "Usage: ./buildpackage <target> <version> [<release>]"
	print " target is the 'distro name', or 'universal' for all mac builds"
	print " Example: ./buildpackage macos-10-ppc 1.1.13.2 1"
	print "          ./buildpackage universal 1.2"
	sys.exit(1)

if target == 'universal':
	build_universal = True
	# Sub x86 for universal
	target = archs[0].replace(archs[0].split('-')[2], 'universal')
	arch_name = 'universal'
	build_host = archs[0]
	targets = archs
else:
	build_universal = False
	arch_name = target.split('-')[2]
	build_host = target
	targets = [ target ]

env = packaging.buildenv(build_host, print_output=debug)

remote_temp = "/tmp/packaging"
resources_dir = remote_temp + os.sep + 'resources'
remote_PKGROOT = remote_temp + os.sep + 'PKGROOT'
remote_packages_loc = remote_temp + os.sep + 'install-packages'
temp_dir = "build" + os.sep + target

output_dir = os.path.join("output", version, target, release) 

if os.path.exists(output_dir):
	print "%s exists, bump release number" % output_dir
	sys.exit(1)

# Keep list of files used to build this package
packages_used = []
versions = {}

# Clean up
env.ssh.execute('rm -Rf ' + remote_temp + "; mkdir -p " + remote_PKGROOT)

for arch in targets:

	arch_env = packaging.buildenv(arch, print_output=debug)
	# Get list of files we're going to install
	files = []
	for pac in packages_to_include[arch]:
		package = packaging.package(arch_env, pac)
		versions[pac] = package.get_version()
		files += package.get_files()
		files += package.get_dep_files()

	# Remove duplicates
	files = utils.remove_list_duplicates(files)

	packages_used += map(os.path.basename, files)

	# Add helper files to the list
	files += [config.packaging_dir + '/do-install-zip-pkgs']
	files += [config.packaging_dir + '/../pyutils/utils.py']
	files += [config.packaging_dir + '/../pyutils/rpm2cpio.py']
	files += ['./universal_merge']

	for file in files:
		print file

	arch_remote_packages_loc = remote_packages_loc + os.sep + arch
	arch_remote_PKGROOT = remote_PKGROOT + '_' + arch

	# Create dirs
	env.ssh.execute('mkdir -p %s %s %s' % (arch_remote_packages_loc, arch_remote_PKGROOT, resources_dir) )

	# Copy them over...
	env.ssh.copy_to(files, arch_remote_packages_loc, mode='scp', compress=0)

	# This will unpack and do all the substitution, including the noarch rpms
	env.ssh.print_output=debug
	framework_prefix = "/Library/Frameworks/Mono.framework"
	prefix = "%s/Versions/%s" % (framework_prefix, version)
	(code, output) = env.ssh.execute("%s/do-install-zip-pkgs %s%s %s %s/* " % (arch_remote_packages_loc, arch_remote_PKGROOT, prefix, prefix, arch_remote_packages_loc) )
	if code:
		print "Error extracting and installing packages"
		sys.exit(1)


# Done laying down files

# Lipo archs together if we're doing universal
if build_universal:
	(code, output) = env.ssh.execute("cd %s; %s/universal_merge %s PKGROOT" % (remote_temp, arch_remote_packages_loc, " ".join(archs) ) )

# Otherwise, just move the one arch into PKGROOT
else:
	(code, output) = env.ssh.execute("cd %s; rmdir PKGROOT; mv %s PKGROOT " % (remote_temp, 'PKGROOT_' + target) )


#### Strip files to save space

# These were in the old script as "cleanup"
env.ssh.print_command=1
# Hmm... stripping all dylibs causes issues on mac x86 as well as for libgdiplus on both plats, only strip some
# Fixed: use -S on dylibs and .a files.  But, shipping unstripped binaries generates better stack traces

# Don't strip these files
unstripped_bins = "mono"
unstripped_libs = "libgdiplus*dylib lib*ono*dylib libikvm*dylib"
env.ssh.execute("cd %s%s/bin; mv %s ..;  strip *; cd ..; mv %s bin " % (remote_PKGROOT, prefix, unstripped_bins, unstripped_bins ) )
env.ssh.execute("cd %s%s/lib; mv %s ..;  strip -S *.dylib *.a; cd ..; mv %s lib" % (remote_PKGROOT, prefix, unstripped_libs, unstripped_libs ) )
# Still caused problems linking... but this doesn't seem to matter

# This is what the old installer script would do, except it deleted the .a files instead of stripping them
#env.ssh.execute("cd %s%s/bin; strip pedump monodiet monodis jay monograph; cd ../lib strip -S *.a " % (remote_PKGROOT, prefix) )

# Miguel doesn't want to ship the .a files
env.ssh.execute("cd %s%s/lib; rm -f *.a" % (remote_PKGROOT, prefix) )

if os.path.exists(temp_dir): shutil.rmtree(temp_dir)
distutils.dir_util.mkpath(temp_dir)

print "Saving list of packages..."
packages_used = utils.remove_list_duplicates(packages_used)
packages_used.sort()
fd = open("%s/packages_used.txt" % temp_dir, 'w')
for file in packages_used:
	fd.write(file + "\n")
fd.close()

#  Get some version information
mono_package = packaging.package(env, 'mono')
revision = mono_package.get_revision(release)

# Start process of making the package
package_filename = "MonoFramework-%s_%s.%s" % (version, revision, arch_name)

# Substitue versions in setup files
parameter_map = {}
parameter_map[re.compile("@@MONO_VERSION@@")] = version
parameter_map[re.compile("@@MONO_RELEASE@@")] = release
parameter_map[re.compile("@@MONO_VERSION_RELEASE@@")] = version + '_' + release
parameter_map[re.compile("@@COCOASHARP_VERSION@@")] = versions['cocoa-sharp']
parameter_map[re.compile("@@LIBGDIPLUS_VERSION@@")] = versions['libgdiplus']
parameter_map[re.compile("@@XSP_VERSION@@")] = versions['xsp']
parameter_map[re.compile("@@MONODOC_VERSION@@")] = versions['monodoc']
parameter_map[re.compile("@@BOO_VERSION@@")] = versions['boo']
parameter_map[re.compile("@@IKVM_VERSION@@")] = versions['ikvm']
parameter_map[re.compile("@@MONO_PACKAGE_FILENAME@@")] = package_filename + ".pkg"

cwd = os.getcwd()

for file in os.listdir(cwd + os.sep + 'setup-files'):
	# Skip directories (.svn in particular)
	if not os.path.isdir(file):
		shutil.copy('setup-files' + os.sep + file, temp_dir)
		utils.substitute_parameters_in_file(temp_dir + os.sep + file, parameter_map)

os.chdir(temp_dir)

# Copy files to resources_dir
env.ssh.copy_to('version.plist License.rtf ReadMe.rtf Welcome.rtf uninstallMono.sh postflight'.split(), resources_dir, mode='scp')

framework_resources_dir = "%s%s/Versions/%s/Resources" % (remote_PKGROOT, framework_prefix, version)
env.ssh.execute('mkdir -p %s' % framework_resources_dir )

env.ssh.copy_to('Info.plist Description.plist version.plist'.split(), framework_resources_dir, mode='scp')

os.chdir(cwd)

# Testing options
env.ssh.print_command=1
#env.ssh.execute_command=0

print "Creating symlinks..."
env.ssh.execute('cd %s%s/Versions; ln -sf %s Current' % (remote_PKGROOT, framework_prefix, version) )

symlinks = {}
symlinks['Versions/Current/Resources'] 	= "Resources"
symlinks['Versions/Current/lib'] 	= "Libraries"
symlinks['Versions/Current/include'] 	= "Headers"
symlinks['Versions/Current/bin'] 	= "Commands"
symlinks['Versions/Current'] 		= "Home"
symlinks['Libraries/libmono.dylib']	= "Mono"

for k,v in symlinks.iteritems():
	env.ssh.execute('cd %s%s; ln -sf %s %s' % (remote_PKGROOT, framework_prefix, k, v) )

print "Done creating symlinks...."

# Note: DiskManagementTool hangs this has been fixed in 10.4 ( http://lists.apple.com/archives/installer-dev/2005/Jul/msg00005.html )
#  This doesn't happen all the time... in fact, never on macbld1.provo.novell.com running 10.3 ... ?
# Maybe we make sudo not ask for a password and then prepend this with sudo?

# Scan for Text: PackageMaker[15625] done (0)
# and then terminate
exit_reg = ""
#exit_reg = re.compile('PackageMaker.* done \(.*\)')

# TODO: need to figure out how to set 'Allows Back Rev.' flag, or possibly clean up 'receipt'

packagemaker = "/Developer/Applications/Utilities/PackageMaker.app/Contents/MacOS/PackageMaker"
env.ssh.execute('cd %s; %s -build -p %s/%s.pkg -f %s -r %s -i %s/Info.plist -d %s/Description.plist' % (remote_PKGROOT, packagemaker, remote_temp, package_filename, remote_PKGROOT, resources_dir, framework_resources_dir, framework_resources_dir), terminate_reg=exit_reg)

env.ssh.execute('/usr/bin/hdiutil create -ov -srcfolder %s/%s.pkg -volname MonoFramework-%s %s/%s.dmg' % (remote_temp, package_filename, version, remote_temp, package_filename) )

distutils.dir_util.mkpath(output_dir)

print "Copy package back..."
# Have to use scp mode here, because I don't want the remote_temp dir in the filename
# Also, use no compression, since file is already compressed
env.ssh.copy_from("%s/%s.dmg" % (remote_temp, package_filename), output_dir, mode='scp', compress=0)

# Create md5
print "Create md5..."
utils.launch_process("cd %s; md5sum %s.dmg > %s.dmg.md5 " % (output_dir, package_filename, package_filename), print_output=debug)

print "Saving packages_used.txt..."
shutil.copy(temp_dir + os.sep + 'packages_used.txt', output_dir)


